name: CI/CD para DigitalOcean

on:
  push:
    branches:
      - main

# ⚠️ SECRETS NECESSÁRIOS NO GITHUB (Settings > Secrets and variables > Actions)
# 
# DATABASE:
#   - DATABASE_NAME: capacita
#   - DATABASE_USER: root (ou outro)
#   - DATABASE_PASSWORD: sua-senha-do-banco
#
# AWS S3:
#   - AWS_ACCESS_KEY_ID: seu-access-key
#   - AWS_SECRET_ACCESS_KEY: seu-secret-key
#   - AWS_REGION: us-east-1
#
# AWS SES (Email - IMPORTANTE!):
#   1. AWS Console → SES → Account dashboard
#      - Request production access (demora ~1 dia)
#      - Verified Identities: adicione seu email/domínio
#   2. SES → SMTP Settings → Create SMTP Credentials
#   3. Adicione nos GitHub Secrets:
#      - AWS_SES_SMTP_USER: seu-usuario-smtp (gerado pelo AWS)
#      - AWS_SES_SMTP_PASSWORD: sua-senha-smtp (gerada pelo AWS)
#
# SSH:
#   - DROPLET_SSH_KEY: sua-chave-privada-ssh
#   - REMOTE_HOST: seu-ip-do-servidor
#   - REMOTE_USER: seu-usuario-do-servidor
#
# Veja: docs/NOTIFICACOES_RABBITMQ.md para mais detalhes

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout do código
      - name: Checkout do Repositório
        uses: actions/checkout@v4

      # 2. Configuração do ambiente Java/Maven (inicia aqui - front-end ignorado)
      - name: BE - Configurar JDK
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin' # ou a distribuição que preferir
          java-version: '21'
          cache: 'maven' # Configura cache do Maven para acelerar builds futuros

      # 4. Geração do .jar (executa no diretório raiz do repositório)
      - name: BE - Gerar Artefato .JAR
        run: mvn package -DskipTests=true

      # 5. Dando o mesmo nome sempre ao .jar
      - name: BE - Renomear JAR para app_loko.jar
        run: |
          set -e
          JAR_NAME=$(ls target/*.jar | head -n 1)
          mv "$JAR_NAME" target/app_loko.jar
          echo "Renomeado para: target/app_loko.jar"
        # rodar no diretório raiz onde está o pom.xml/target
        working-directory: .

      # 6. Copiar JAR diretamente para o local de produção (/usr/share/api) usando rsync com sudo remoto
      - name: BE - Copiar JAR para /usr/share/api (rsync com sudo remoto)
        uses: easingthemes/ssh-deploy@main
        with:
          SSH_PRIVATE_KEY: ${{ secrets.DROPLET_SSH_KEY }}
          REMOTE_HOST: ${{ secrets.REMOTE_HOST }}
          REMOTE_USER: ${{ secrets.REMOTE_USER }}
          # alvo final no servidor (rsync criará o arquivo app_loko.jar neste diretório)
          TARGET: /usr/share/api/
          # ARGS: usa --rsync-path para criar o diretório com sudo e executar rsync como sudo
          ARGS: "-rltgoDzvO --delete --rsync-path=\"sudo mkdir -p /usr/share/api && sudo rsync\""
          SOURCE: "./target/app_loko.jar"

      # 7. Reiniciar o serviço na Droplet (apenas reinício; upload já foi direto para /usr/share/api)
      - name: BE - Reiniciar serviço na Droplet
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.REMOTE_HOST }}
          username: ${{ secrets.REMOTE_USER }}
          key: ${{ secrets.DROPLET_SSH_KEY }}
          script: |
            set -e
            echo "Reiniciando serviço 'api' na Droplet"
            
            # Define o caminho do compose (ajuste se necessário)
            COMPOSE_FILE="/root/compose.yaml"
            
            # Se o usuário não for root, tenta no home do usuário
            if [ ! -f "$COMPOSE_FILE" ]; then
              COMPOSE_FILE="/home/${{ secrets.REMOTE_USER }}/compose.yaml"
            fi
            
            echo "Usando compose: $COMPOSE_FILE"
            
            # Cria/atualiza arquivo .env no mesmo diretório do compose com variáveis do banco
            COMPOSE_DIR=$(dirname "$COMPOSE_FILE")
            ENV_FILE="$COMPOSE_DIR/.env"
            
            echo "Criando/atualizando arquivo .env em: $ENV_FILE"
            # Use explicit echo lines instead of an indented heredoc to avoid YAML indentation
            # being included in the remote file (which would corrupt the .env).
            
            # ========== DATABASE ==========
            echo "DATABASE_NAME=${{ secrets.DATABASE_NAME }}" > "$ENV_FILE"
            echo "DATABASE_USER=${{ secrets.DATABASE_USER }}" >> "$ENV_FILE"
            echo "DATABASE_PASSWORD=${{ secrets.DATABASE_PASSWORD }}" >> "$ENV_FILE"
            
            # ========== AWS S3 ==========
            echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> "$ENV_FILE"
            echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> "$ENV_FILE"
            echo "AWS_REGION=${{ secrets.AWS_REGION }}" >> "$ENV_FILE"
            
            # ========== AWS SES (Email) ==========
            echo "MAIL_HOST=email-smtp.us-east-1.amazonaws.com" >> "$ENV_FILE"
            echo "MAIL_PORT=587" >> "$ENV_FILE"
            echo "MAIL_USERNAME=${{ secrets.AWS_SES_SMTP_USER }}" >> "$ENV_FILE"
            echo "MAIL_PASSWORD=${{ secrets.AWS_SES_SMTP_PASSWORD }}" >> "$ENV_FILE"
            
            # ========== SPRING CONFIG ==========
            echo "HIBERNATE_DDL_AUTO=none" >> "$ENV_FILE"
            echo "SHOW_SQL=false" >> "$ENV_FILE"
            
            echo "Arquivo .env criado/atualizado com secrets do GitHub"
            
            # Reinicia o serviço (down + up para garantir que o .env seja lido)
            sudo docker compose -f "$COMPOSE_FILE" down || true
            sudo docker compose -f "$COMPOSE_FILE" up -d
            
            echo "Serviço reiniciado em: ${{ secrets.REMOTE_HOST }}"
            
            # Aguarda alguns segundos e mostra logs
            sleep 5
            echo "Logs do container (últimas 50 linhas):"
            sudo docker compose -f "$COMPOSE_FILE" logs --tail=50 api
